NanoSAM-ONNX · Evaluación con prompts y métricas

Este cuaderno evalúa NanoSAM exportado a ONNX (encoder y decoder con ONNX Runtime) sobre un conjunto de datos de PCB, midiendo IoU, Dice, Precisión, Recall y tiempo a 1024×1024 con diferentes prompts. Está pensado para Google Colab con versiones fijas (NumPy 1.26.4, OpenCV 4.8.1.78, ONNX Runtime 1.17.3; opcionalmente onnxruntime-gpu 1.17.3). Los modelos resnet18_image_encoder.onnx y mobile_sam_mask_decoder.onnx deben estar en /content/drive/MyDrive/Colab Notebooks/TFG/NanoSam/, y las imágenes + anotaciones .json en /content/drive/MyDrive/Colab Notebooks/SolDef_AI/Labeled/; a partir de los .json se rasterizan máscaras binarias en generated_masks/. El flujo monta Drive, clona el repo oficial de NanoSAM, limpia caches e instala dependencias; luego carga los ONNX y verifica entradas y salidas. Cada imagen se preprocesa, se normaliza tipo ImageNet y se convierte a NCHW float32; el encoder produce embeddings (1,256,64,64) que, junto a coordenadas de prompts (positivos=1) y sin máscara previa, se pasan al decoder para obtener cuatro hipótesis (logits 256×256) y sus iou_predictions. Se elige la hipótesis con mayor IoU predicho, se binariza (logit>0 ≡ p>0.5), se reescala a 1024 y opcionalmente al tamaño original para visualización. Se evalúan cuatro modalidades de prompt (point, box, box+point, multipoint) y un barrido por número de puntos K, computando métricas en 1024 y registrando tiempos; se guardan visualizaciones
